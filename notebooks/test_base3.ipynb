{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMotCHD8kdxVBc43IUCPscy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zenAurelius/HRAI3/blob/main/notebooks/test_base3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5xoN2-d47Yz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/HRAI/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw = pd.read_csv('pmu2017_os.zip')\n",
        "list(dfraw.columns)"
      ],
      "metadata": {
        "id": "J1urUMxy_WfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux une concatenation de pff_tendanceReference_1 et pff_tendanceReference_2 mais en remplacant dans chaque colonne 0 par + 0.5 par = et 1 par -\n",
        "\n",
        "def replace_values(value):\n",
        "  if value == 0:\n",
        "    return '+'\n",
        "  elif value == 0.5:\n",
        "    return '='\n",
        "  elif value == 1:\n",
        "    return '-'\n",
        "  else:\n",
        "    return value\n",
        "\n",
        "dfraw['pfs_dTendanceReference'] = (\n",
        "    dfraw['pff_tendanceReference_1'].apply(replace_values).astype(str) +\n",
        "    dfraw['pff_tendanceReference_2'].apply(replace_values).astype(str)\n",
        ")\n",
        "\n",
        "dfraw['pfs_dTendanceReference']\n"
      ],
      "metadata": {
        "id": "z5mOqOu2CSgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw['pfs_dTendanceReference'].value_counts()"
      ],
      "metadata": {
        "id": "6VcorVHfBj2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux la proportion de tgf_win_1 = 1 pour chaque valeur possible de dfraw['pfs_dTendanceReference']\n",
        "\n",
        "# Group by 'pfs_dTendanceReference' and calculate the proportion of 'tgf_win_1' equal to 1\n",
        "proportion_tgf_win_1 = dfraw.groupby('pfs_dTendanceReference')['tgf_win_1'].mean()\n",
        "\n",
        "proportion_tgf_win_1\n"
      ],
      "metadata": {
        "id": "1drM28OGEoHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw = dfraw[~dfraw.pff_rapportDirect_1.isna()].copy()\n",
        "dfraw['win_cote'] = (dfraw.pff_rapportDirect_1 < dfraw.pff_rapportDirect_2).astype(int)\n",
        "dfraw[['win_cote','pff_rapportDirect_1', 'pff_rapportDirect_2']]\n",
        "dfraw['pff_dOrd'] = dfraw.pff_ord_1 - dfraw.pff_ord_2\n",
        "dfraw['pff_dMuC'] = dfraw.pff_mu_pis_cheval_1 - dfraw.pff_mu_pis_cheval_2\n",
        "dfraw['pff_dMuD'] = dfraw.pff_mu_pis_driver_1 - dfraw.pff_mu_pis_driver_2"
      ],
      "metadata": {
        "id": "XQeBn43NNc5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete(df, cols):\n",
        "  cols_complete = []\n",
        "  for b in (cols):\n",
        "    if(b.endswith('_')):\n",
        "      cols_complete.append(b + '1')\n",
        "      cols_complete.append(b + '2')\n",
        "    else:\n",
        "      cols_complete.append(b)\n",
        "  return cols_complete\n",
        "\n",
        "def calc_ratio(df, ratio, num_features):\n",
        "    for col in ratio:\n",
        "      col1 = col + '1'\n",
        "      col2 = col + '2'\n",
        "      if col2 in df.columns:\n",
        "        df[f'{col}ratio'] = (df[col1] / (df[col1] + df[col2])).replace([np.inf, -np.inf, np.nan], 0.5).fillna(0.5)\n",
        "        df[f'win_{col}'] = (df[f'{col}ratio'] > 0.5).astype(int)\n",
        "        num_features.append(f'{col}ratio')\n",
        "        #num_features.append(col1)\n",
        "    return df\n",
        "\n",
        "\n",
        "# INIT FEATURES/TARGET/CONST\n",
        "NONFEATURES = ['aid_cr', 'pis_cheval_', 'tgi_ordreArrivee_', 'pff_rapportDirect_1', 'tgb_estGagnant_1', 'tgb_estPlace_1', 'win_cote']\n",
        "NONFEATURES = complete(dfraw, NONFEATURES)\n",
        "# Les features liées à la cotes : 'pff_normcote_','pff_rapportDirect_','pff_rapportReference_',\n",
        "RATIO_F = ['pfi_chAge_', 'pfi_chNbCourses_','pfi_chNbVictoires_','pfi_chNbPlaces_','pfi_chNbSecond_','pfi_chNbTroisieme_','pff_chGainTotal_','pff_chGainVictoire_','pff_chGainPlace_','pff_chGainAnnee_','pff_chGainAnneePrec_','pff_handicap_','pfi_placeCorde_','pff_txReclamation_']\n",
        "#RATIO_F = []\n",
        "NUM_FEATURES = ['rfi_nbPartants','rff_temperature','rfi_ventForce','pfb_chInedit_1','pff_dOrd']\n",
        "#NUM_FEATURES = ['pff_dMuC','pff_dMuD','pff_sgsq_1','pff_sgsq_2']\n",
        "CAT_FEATURES = ['pfs_dSexe', 'pfs_dTendanceReference']\n",
        "#CAT_FEATURES = []\n",
        "CAT_FEATURES_VOCAB = {\n",
        "    'pfs_dSexe': ['FF', 'FM', 'FH', 'HF', 'HM', 'HH', 'MM', 'MF', 'MH'],\n",
        "    'pfs_dTendanceReference': ['++','+=','+-','=+','==','=-','-+','-=','--']\n",
        "}\n",
        "dfraw = calc_ratio(dfraw, RATIO_F, NUM_FEATURES)\n",
        "FEATURES = NUM_FEATURES + CAT_FEATURES\n",
        "\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "MT_REG = 'regression'\n",
        "MT_CLA = 'classification'\n",
        "MODEL_TYPE = MT_REG\n",
        "if MODEL_TYPE == 'classification':\n",
        "  TARGET = ['tgf_win_1']\n",
        "  NONFEATURES.append('tgf_pwin_1')\n",
        "else:\n",
        "  TARGET = ['tgf_pwin_1']\n",
        "  NONFEATURES.append('tgf_win_1')\n",
        "ALL_COLS = FEATURES + TARGET\n",
        "\n",
        "df = dfraw[ALL_COLS + NONFEATURES].copy()\n",
        "df"
      ],
      "metadata": {
        "id": "YbFltuLRi9QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPLIT TRAIN, TEST, VAL\n",
        "\n",
        "limit_train = df['aid_cr'].iloc[int(0.8 * len(df))]\n",
        "limit_val = df['aid_cr'].iloc[int(0.9 * len(df))]\n",
        "print(limit_train, limit_val)\n",
        "train = df[df.aid_cr < limit_train].copy()\n",
        "val = df[(df.aid_cr >= limit_train) & (df.aid_cr < limit_val)].copy()\n",
        "test = df[df.aid_cr >= limit_val].copy()\n",
        "print(len(train), 'training examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "metadata": {
        "id": "1N6jE-CDEGf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train[NUM_FEATURES] = scaler.fit_transform(train[NUM_FEATURES])\n",
        "val[NUM_FEATURES] = scaler.transform(val[NUM_FEATURES])\n",
        "test[NUM_FEATURES] = scaler.transform(test[NUM_FEATURES])"
      ],
      "metadata": {
        "id": "n0vpACac4lqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERSIONS INPUT\n",
        "\n",
        "# DF TO DATASET\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  df = dataframe[ALL_COLS].copy()\n",
        "  labels = df.pop(TARGET[0])\n",
        "  df = {key: np.array(value)[:,tf.newaxis] for key, value in df.items()}\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(df))\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(batch_size)\n",
        "  return ds\n",
        "\n",
        "# GET INPUT LAYER\n",
        "def get_input_layer(name, dataset):\n",
        "  print(name)\n",
        "  # normalizer = layers.Normalization(axis=None)\n",
        "  # Récupère un dataset avec seulement les colonnes passées dans 'name'\n",
        "  #feature_ds = dataset.map(lambda x, y: x[name])\n",
        "  #print(feature_ds)\n",
        "  #layers.Input(\n",
        "  return layers.Input( name=name, shape=(), dtype=\"float32\" )\n",
        "  #normalizer.adapt(feature_ds)\n",
        "  #return normalizer\n",
        "\n",
        "# GET NORMALIZATION LAYER\n",
        "def get_normalization_layer(name, dataset):\n",
        "  print(name)\n",
        "  normalizer = layers.Normalization(axis=None)\n",
        "  # Récupère un dataset avec seulement les colonnes passées dans 'name'\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "  print(feature_ds)\n",
        "  normalizer.adapt(feature_ds)\n",
        "  return normalizer\n",
        "\n",
        "# GET CATEGORY ENCODING LAYER\n",
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  # Lookup Layer, soit StringLookup, soit IntergerLookup\n",
        "  if dtype == 'string':\n",
        "    vocabulary = CAT_FEATURES_VOCAB[name]\n",
        "    index = layers.StringLookup(\n",
        "                vocabulary=vocabulary,\n",
        "                mask_token=None,\n",
        "                num_oov_indices=0,\n",
        "                output_mode=\"binary\"\n",
        "            )\n",
        "  else:\n",
        "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  return index"
      ],
      "metadata": {
        "id": "EGN-5w56EY-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DATASET\n",
        "\n",
        "train_ds = df_to_dataset(train, shuffle=False, batch_size=BATCH_SIZE)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=BATCH_SIZE)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "E6dvUbuzHs82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_inputs = {}\n",
        "encoded_features = []\n",
        "import keras\n",
        "\n",
        "#for header in NUM_FEATURES:\n",
        "for header in NUM_FEATURES:\n",
        "  numeric_col = tf.keras.Input(shape=(), name=header, dtype='float32')\n",
        "  #normalization_layer = get_normalization_layer(header, train_ds)\n",
        "  #encoded_numeric_col = normalization_layer(numeric_col)\n",
        "  encoded_numeric_col = keras.ops.expand_dims(numeric_col,-1)\n",
        "  all_inputs[header] = numeric_col\n",
        "  encoded_features.append(encoded_numeric_col)\n",
        "\n",
        "for header in CAT_FEATURES:\n",
        "  categorical_col = tf.keras.Input(shape=(), name=header, dtype='string')\n",
        "  lookup = get_category_encoding_layer(header, dataset=train_ds, dtype='string', max_tokens=9)\n",
        "  encoded_feature = lookup( keras.ops.expand_dims(categorical_col, -1))\n",
        "  all_inputs[header] = categorical_col\n",
        "  encoded_features.append(encoded_feature)"
      ],
      "metadata": {
        "id": "TK-D-jL6HMBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL REGRESSION\n",
        "all_features = tf.keras.layers.concatenate(encoded_features)\n",
        "x = tf.keras.layers.Dense(128, activation=\"relu\")(all_features)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "output = tf.keras.layers.Dense(1)(x)\n",
        "print(encoded_features)\n",
        "\n",
        "model = tf.keras.Model(all_inputs, output)\n",
        "if(MODEL_TYPE == MT_REG):\n",
        "  model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "else:\n",
        "  model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"],\n",
        "              run_eagerly=True)"
      ],
      "metadata": {
        "id": "HVsx5ZycuYhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use `rankdir='LR'` to make the graph horizontal.\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n"
      ],
      "metadata": {
        "id": "GVyqNNABLyot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, epochs=4, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "pblhIixEMKbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, ds, df, pcol):\n",
        "  predictions = model.predict(ds)\n",
        "  df[pcol] = predictions\n",
        "  threshold = 0.5\n",
        "  df[f'{pcol}_w'] = (predictions > threshold).astype(int)\n",
        "\n",
        "  # Le reste pourrait être ailleurs\n",
        "def prepare_comparaison(df):\n",
        "  df['win1'] = (df.tgf_pwin_1 > 0.5).astype(int)\n",
        "\n",
        "  #df['win_ord'] = (df.pff_dOrd > 0.5).astype(int)\n",
        "  #df['win_gain'] = (df.pff_dGain > 0.5).astype(int)\n",
        "\n",
        "def eval(df, pcol):\n",
        "  print('positifs')\n",
        "  print(len(df[(df[f'{pcol}_w'] == 1) & (df.win1 == 1)]) / len(df[(df.win1 == 1)]))\n",
        "  print(len(df[(df.win_cote == 1) & (df.win1 == 1)]) / len(df[(df.win1 == 1)]))\n",
        "  #print(len(df[(df.win_ord == 1) & (df.win1 == 1)]) / len(df[(df.win1 == 1)]))\n",
        "  print('negatifs')\n",
        "  print(len(df[(df[f'{pcol}_w'] == 0) & (df.win1 == 0)]) / len(df[(df.win1 == 0)]))\n",
        "  print(len(df[(df.win_cote == 0) & (df.win1 == 0)]) / len(df[(df.win1 == 0)]))\n",
        "  #print(len(df[(df.win_ord == 0) & (df.win1 == 0)]) / len(df[(df.win1 == 0)]))"
      ],
      "metadata": {
        "id": "GPTpNe1kvW0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, train_ds, train, 'pred')\n",
        "prepare_comparaison(train)\n",
        "eval(train, 'pred')"
      ],
      "metadata": {
        "id": "I5ggAKtvfT-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, test_ds, test, 'pred')\n",
        "prepare_comparaison(test)\n",
        "eval(test, 'pred')"
      ],
      "metadata": {
        "id": "gX8m68URirsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pct_place(df):\n",
        "    n = len(df)\n",
        "    npl = len(df[df.tgb_estPlace_1])\n",
        "    nga = len(df[df.tgb_estGagnant_1])\n",
        "    print(f'placé {100 * npl / n:.2f}%  [{npl}/{n}] - gagnant {100 * nga / n:.2f}% [{nga}/{n}]')\n",
        "    df['gain_gagnant'] = np.where(df['tgb_estGagnant_1'], df['pff_rapportDirect_1']-1, -1)\n",
        "    print(f'gain gagnant = {df.gain_gagnant.sum()}')"
      ],
      "metadata": {
        "id": "khXf9uNx5WHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = test.groupby(['aid_cr', 'pis_cheval_1']).first().reset_index()\n",
        "bycr = result.groupby('aid_cr')\n",
        "result['pred_R'] = bycr['pred'].rank(ascending=False)\n",
        "pct_place(result[result['pred_R'] == 1.0].copy())\n",
        "pct_place(result[result['pred_R'] == 2.0].copy())\n",
        "pct_place(result[result['pred_R'] == 3.0].copy())\n",
        "result['cote_R'] = bycr['pff_rapportDirect_1'].rank(ascending=True)\n",
        "pct_place(result[result['cote_R'] == 1.0].copy())\n",
        "pct_place(result[result['cote_R'] == 2.0].copy())\n",
        "pct_place(result[result['cote_R'] == 3.0].copy())"
      ],
      "metadata": {
        "id": "QhcZ0KEC71l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTS**"
      ],
      "metadata": {
        "id": "oBjUB3qkitM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw[dfraw.pff_ord__ratio > 10][['pff_ord__ratio','pff_ord_1','pff_ord_2']]"
      ],
      "metadata": {
        "id": "WXMDdorqqgnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux un graph en nuage de point montrant la relation entre dfraw.pff_ord_ratio et defraw.tgf_win_1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = dfraw.tail(1000).copy()\n",
        "df['d_ord'] = df.pff_ord_1 - df.pff_ord_2\n",
        "print(df.d_ord.value_counts())\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(df.d_ord, df.tgf_pwin_1)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('dfraw.pff_ord_ratio')\n",
        "plt.ylabel('dfraw.tgf_win_1')\n",
        "plt.title('Relationship between pff_ord_ratio and tgf_win_1')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qCWyudBdqAFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw.pff_favorisReference_1.value_counts()"
      ],
      "metadata": {
        "id": "ZL9GasfjuieX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Pour toutes les colonnes qui commencent par 'pfi' ou 'pff' et finissent par '1' du dataframe dfraw, je voudrais calculer le rapport de la colonne qui fini par 1 avec la même colonnes mais finissant par '2'\n",
        "\n",
        "\n",
        "# Assuming 'dfraw' is your DataFrame and it's already loaded as in your provided code\n",
        "\n",
        "def calculate_ratio(df):\n",
        "    for col in df.columns:\n",
        "        if (col.startswith('pfi') or col.startswith('pff')) and col.endswith('1'):\n",
        "            rootc = col[:-1]\n",
        "            print(rootc)\n",
        "            col2 = rootc + '2'  # Construct the corresponding column name ending with '2'\n",
        "            if col2 in df.columns:\n",
        "                df[f'{rootc}_ratio'] = df[col] / (df[col] + df[col2])\n",
        "                df[f'win_{rootc}'] = (df[f'{rootc}_ratio'] > 0.5).astype(int)\n",
        "                print(df[df[f'win_{rootc}'] == 1].tgf_win_1.value_counts())\n",
        "            else:\n",
        "                print(f\"Warning: Column '{col2}' not found for '{col}'. Ratio calculation skipped.\")\n",
        "    return df\n",
        "\n",
        "dfraw = calculate_ratio(dfraw)\n"
      ],
      "metadata": {
        "id": "0gamB7vtsNZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['win_nbv'] = (df.pfi_dNbVictoires > 0.5).astype(int)\n",
        "df['win_gain'] = (df.pff_dGain > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "E8NfeSSpqi-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.win_gain == 1].tgf_win_1.value_counts()"
      ],
      "metadata": {
        "id": "m0MhP03Pq2rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.win_nbv == 0].tgf_win_1.value_counts()"
      ],
      "metadata": {
        "id": "HCTCJzFprDir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux la première moitié des enregistrements de test\n",
        "\n",
        "# Get the first half of the test dataset\n",
        "half_test = int(len(test) / 2)\n",
        "first_half_test = test.head(half_test)\n",
        "\n",
        "# Now you can work with the first_half_test DataFrame\n",
        "print(len(first_half_test), 'first half of test examples')\n",
        "# Example: Print the first few rows\n",
        "print(first_half_test.head())\n"
      ],
      "metadata": {
        "id": "uFq0-L3WjQR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "half_test = int(len(test) / 2)\n",
        "train0 = test.head(half_test)\n",
        "train1 = test.tail(half_test)\n",
        "print(len(train0[(train0.win_ord == 1) & (train0.win1 == 1)]) / len(train0[(train0.win1 == 1)]))\n",
        "print(len(train1[(train1.win_ord == 1) & (train1.win1 == 1)]) / len(train1[(train1.win1 == 1)]))"
      ],
      "metadata": {
        "id": "-b3fqt2qi_DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux selectionner tout les enregistrements ou OS_N_SG_pis_cheval_1 est supérieur à sa valeur médiane\n",
        "\n",
        "median_value = dfraw['OS_N_SG_pis_cheval_1'].median()\n",
        "filtered_df = dfraw[dfraw['OS_N_SG_pis_cheval_1'] < median_value].copy()\n",
        "\n",
        "# prompt: sur ce qui reste que je veux connaitre la valeur moyenne de OS_N_MU_pis_cheval_1 pour chaque quartile de pff_chGainTotal_1\n",
        "\n",
        "# Calculate quartiles for pff_chGainTotal_1\n",
        "filtered_df['quartile'] = pd.qcut(filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'], 4, labels=False)\n",
        "\n",
        "# Group by quartile and calculate the mean of OS_N_MU_pis_cheval_1\n",
        "mean_by_quartile = filtered_df.groupby('quartile')['OS_N_MU_pis_cheval_1'].mean()\n",
        "\n",
        "mean_by_quartile"
      ],
      "metadata": {
        "id": "2LdTb0He1H3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: pour tout les enregistrement où pff_mu_pis_cheval_1 est = 25, je veux que la valeur soit remplacé par 24 si pff_chGainTotal_1 / pfi_chNbCourses_1 < 110000, par 29 si >110000 et <174000, par 32 si >174000 et <285000 et par 36 si > 285000\n",
        "\n",
        "# Create a copy to avoid SettingWithCopyWarning\n",
        "filtered_df = filtered_df.copy()\n",
        "\n",
        "# Apply the conditions and update pff_mu_pis_cheval_1\n",
        "filtered_df.loc[\n",
        "    (filtered_df['pff_mu_pis_cheval_1'] == 25) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] < 110000),\n",
        "    'pff_mu_pis_cheval_1'\n",
        "] = 24\n",
        "\n",
        "filtered_df.loc[\n",
        "    (filtered_df['pff_mu_pis_cheval_1'] == 25) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] >= 110000) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] < 174000),\n",
        "    'pff_mu_pis_cheval_1'\n",
        "] = 29\n",
        "\n",
        "filtered_df.loc[\n",
        "    (filtered_df['pff_mu_pis_cheval_1'] == 25) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] >= 174000) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] < 285000),\n",
        "    'pff_mu_pis_cheval_1'\n",
        "] = 32\n",
        "\n",
        "filtered_df.loc[\n",
        "    (filtered_df['pff_mu_pis_cheval_1'] == 25) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] >= 285000),\n",
        "    'pff_mu_pis_cheval_1'\n",
        "] = 36"
      ],
      "metadata": {
        "id": "CzDm5GKW7rBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux connnaitre les bornes des quartiles de pff_chGainTotal_1 / pfi_chNbCourses_1\n",
        "\n",
        "# Calculate quartiles for pff_chGainTotal_1 / pfi_chNbCourses_1\n",
        "filtered_df['quartile_ratio'] = pd.qcut(filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'], 4, labels=False)\n",
        "\n",
        "# Get the boundaries of each quartile\n",
        "quartiles = filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1']\n",
        "quartile_bounds = quartiles.quantile([0.25, 0.5, 0.75])\n",
        "\n",
        "quartile_bounds"
      ],
      "metadata": {
        "id": "oWtTC-0T509W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.tgf_win_1 != 0.5]\n",
        "print(len(df[(df.pfs_dSexe == 'FF') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'FF')]))\n",
        "print(len(df[(df.pfs_dSexe == 'FM') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'FM')]))\n",
        "print(len(df[(df.pfs_dSexe == 'FH') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'FH')]))\n",
        "print(len(df[(df.pfs_dSexe == 'HF') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'HF')]))\n",
        "print(len(df[(df.pfs_dSexe == 'HM') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'HM')]))\n",
        "print(len(df[(df.pfs_dSexe == 'HH') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'HH')]))\n",
        "print(len(df[(df.pfs_dSexe == 'MM') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'MM')]))\n",
        "print(len(df[(df.pfs_dSexe == 'MF') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'MF')]))\n",
        "print(len(df[(df.pfs_dSexe == 'MH') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'MH')]))"
      ],
      "metadata": {
        "id": "-JxPSCXLSrcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "test_type_col = train_features['diff_sexe']\n",
        "test_type_layer = get_category_encoding_layer(name='diff_sexe',\n",
        "                                              dataset=train_ds,\n",
        "                                              dtype='string',\n",
        "                                              max_tokens=5)\n",
        "test_type_layer(test_type_col)"
      ],
      "metadata": {
        "id": "opBz9AlEYJEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('classifier_test2.keras')\n",
        "reloaded_model = tf.keras.models.load_model('classifier_test.keras')"
      ],
      "metadata": {
        "id": "1fr54u3MuOVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_ds)\n",
        "predictions"
      ],
      "metadata": {
        "id": "Woj0zG9OvCDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux mettre le résultat des prédictions dans une colonne 'pred' du dataframe d'origine 'test'\n",
        "\n",
        "# Convert predictions to a binary classification (e.g., using a threshold)\n",
        "threshold = 0.0\n",
        "binary_predictions = (predictions > threshold).astype(int)\n",
        "\n",
        "# Add the predictions as a new column 'pred' to the test dataframe\n",
        "test['pred'] = binary_predictions\n",
        "\n",
        "# Print the updated dataframe with predictions\n",
        "test.pred.value_counts()"
      ],
      "metadata": {
        "id": "oclHb5ugvOzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.tgf_win_1.value_counts()"
      ],
      "metadata": {
        "id": "HgZi-D7t9m6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: dans dataframe 'test' je veux une colonne win_cote qui contient 1 si rapport 2 > rapport 1 et 0 sinon\n",
        "\n",
        "test['win_cote'] = (test['diff_cote'] < 0.5).astype(int)\n",
        "test['win_ord'] = (test['diff_ord'] > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "c5tiuljozN9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "16uB0_TIj8GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test[(test.pred == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.tgf_win_1 == 1)]))\n",
        "print(len(test[(test.win_cote == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.tgf_win_1 == 1)]))\n",
        "print(len(test[(test.win_ord == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.tgf_win_1 == 1)]))\n",
        "print(len(test[(test.win_cote == 1) & (test.win_ord == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.tgf_win_1 == 1)]))"
      ],
      "metadata": {
        "id": "0xcyWh37zfuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test[(test.pred == 0) & (test.tgf_win_1 == 0)]) / len(test[(test.tgf_win_1 == 0)]))\n",
        "print(len(test[(test.win_cote == 0) & (test.tgf_win_1 == 0)]) / len(test[(test.tgf_win_1 == 0)]))\n",
        "print(len(test[(test.win_ord == 0) & (test.tgf_win_1 == 0)]) / len(test[(test.tgf_win_1 == 0)]))"
      ],
      "metadata": {
        "id": "WP22Lcrs1ras"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test[(test.pred == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.pred == 1)]))\n",
        "print(len(test[(test.pred2 == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.pred2 == 1)]))\n",
        "print(len(test[(test.win_cote == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.win_cote == 1)]))\n",
        "print(len(test[(test.win_ord == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.win_ord == 1)]))\n",
        "print(len(test[(test.win_cote == 1) & (test.win_ord == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.win_cote == 1) & (test.win_ord == 1)]))\n",
        "print(len(test[(test.win_cote == 0) & (test.pred == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.win_cote == 0) & (test.pred == 1)]))"
      ],
      "metadata": {
        "id": "Ey1A4YjiBntS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}