{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMihYVpqiInk0l/qu83eyQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zenAurelius/HRAI3/blob/main/notebooks/test_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5xoN2-d47Yz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/HRAI/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw = pd.read_csv('pmu2017_os.zip')\n",
        "dfraw.head()"
      ],
      "metadata": {
        "id": "J1urUMxy_WfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ajouté à combine.clean\n",
        "dfraw['pfs_chSexe_1'] = dfraw['pfs_chSexe_1'].replace({'FEMELLES': 'F', 'MALES': 'M', 'HONGRES': 'H'})\n",
        "dfraw['pfs_chSexe_2'] = dfraw['pfs_chSexe_2'].replace({'FEMELLES': 'F', 'MALES': 'M', 'HONGRES': 'H'})\n",
        "# ajouté à combine.un_vs_un\n",
        "dfraw['pfs_dSexe'] = dfraw['pfs_chSexe_1'].astype(str) + dfraw['pfs_chSexe_2'].astype(str)"
      ],
      "metadata": {
        "id": "Gb1jHFlUQfh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SELECTION DES FEATURES ET TARGET\n",
        "\n",
        "#df = df[['rfi_prix','rfi_distance','pfi_chNbPlaces_1','pff_rapportDirect_1','pff_ord_1','pfi_chNbPlaces_2','pff_rapportDirect_2','pff_ord_2','tgf_win_1']].copy()\n",
        "#'aid_cr', 'pis_cheval_1','pff_ord_1','pff_ord_2', 'pis_cheval_2','pff_normcote_1'\n",
        "df = dfraw[['aid_cr', 'pis_cheval_1', 'pis_cheval_2', 'pfs_dSexe', 'pff_rapportDirect_1','pff_rapportDirect_2','pff_normcote_1','pff_normcote_2','pff_ord_1','pff_ord_2', 'tgf_pwin_1', 'tgf_win_1']].copy()\n",
        "df = df[(~df.pff_rapportDirect_2.isna()) & (~df.pff_rapportDirect_1.isna())].copy()\n",
        "df['diff_cote'] = df.pff_normcote_1 /  (df.pff_normcote_2 + df.pff_normcote_1)\n",
        "df['diff_ord'] = df.pff_ord_1 /  (df.pff_ord_2 + df.pff_ord_1)\n",
        "df['tgf_win_1'] = df['tgf_win_1'].replace(0.5, 0)\n",
        "df = df[['aid_cr', 'pis_cheval_1', 'pis_cheval_2', 'pfs_dSexe', 'pff_rapportDirect_1', 'pff_ord_1', 'diff_cote','diff_ord', 'tgf_pwin_1','tgf_win_1']].copy()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FvoDWP7VDL_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPLIT TRAIN, TEST, VAL\n",
        "\n",
        "limit_train = df['aid_cr'].iloc[int(0.8 * len(df))]\n",
        "limit_val = df['aid_cr'].iloc[int(0.9 * len(df))]\n",
        "print(limit_train, limit_val)\n",
        "train = df[df.aid_cr < limit_train].copy()\n",
        "val = df[(df.aid_cr >= limit_train) & (df.aid_cr < limit_val)].copy()\n",
        "test = df[df.aid_cr >= limit_val].copy()\n",
        "print(len(train), 'training examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "metadata": {
        "id": "1N6jE-CDEGf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INIT FEATURES/TARGET/CONST\n",
        "\n",
        "NUM_FEATURES = ['diff_cote', 'diff_ord']\n",
        "CAT_FEATURES = ['pfs_dSexe']\n",
        "TARGET = ['tgf_pwin_1']\n",
        "FEATURES = NUM_FEATURES + CAT_FEATURES\n",
        "ALL_COLS = FEATURES + TARGET\n",
        "\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "YbFltuLRi9QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERSIONS INPUT\n",
        "\n",
        "# DF TO DATASET\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  df = dataframe[ALL_COLS].copy()\n",
        "  labels = df.pop(TARGET[0])\n",
        "  df = {key: np.array(value)[:,tf.newaxis] for key, value in df.items()}\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(df))\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(batch_size)\n",
        "  return ds\n",
        "\n",
        "# GET NORMALIZATION LAYER\n",
        "def get_normalization_layer(name, dataset):\n",
        "  normalizer = layers.Normalization(axis=None)\n",
        "  # Récupère un dataset avec seulement les colonnes passées dans 'name'\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "  normalizer.adapt(feature_ds)\n",
        "  return normalizer\n",
        "\n",
        "# GET CATEGORY ENCODING LAYER\n",
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  # Lookup Layer, soit StringLookup, soit IntergerLookup\n",
        "  if dtype == 'string':\n",
        "    index = layers.StringLookup(max_tokens=max_tokens)\n",
        "  else:\n",
        "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  # Récupère un dataset avec seulement les colonnes passées dans 'name'\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Calcul le Lookup\n",
        "  index.adapt(feature_ds)\n",
        "\n",
        "  # Category Encoding à partir du nombre d'index trouvé\n",
        "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
        "\n",
        "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
        "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
        "  return lambda feature: encoder(index(feature))"
      ],
      "metadata": {
        "id": "EGN-5w56EY-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DATASET\n",
        "\n",
        "train_ds = df_to_dataset(train, batch_size=BATCH_SIZE)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=BATCH_SIZE)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "E6dvUbuzHs82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_inputs = {}\n",
        "encoded_features = []\n",
        "\n",
        "for header in NUM_FEATURES:\n",
        "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
        "  normalization_layer = get_normalization_layer(header, train_ds)\n",
        "  encoded_numeric_col = normalization_layer(numeric_col)\n",
        "  all_inputs[header] = numeric_col\n",
        "  encoded_features.append(encoded_numeric_col)\n",
        "\n",
        "for header in CAT_FEATURES:\n",
        "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
        "  encoding_layer = get_category_encoding_layer(name=header,\n",
        "                                               dataset=train_ds,\n",
        "                                               dtype='string',\n",
        "                                               max_tokens=9)\n",
        "  encoded_categorical_col = encoding_layer(categorical_col)\n",
        "  all_inputs[header] = categorical_col\n",
        "  encoded_features.append(encoded_categorical_col)"
      ],
      "metadata": {
        "id": "TK-D-jL6HMBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL CLASSIFICATION\n",
        "\n",
        "all_features = tf.keras.layers.concatenate(encoded_features)\n",
        "x = tf.keras.layers.Dense(16, activation=\"relu\")(all_features)\n",
        "output = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(all_inputs, output)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"],\n",
        "              run_eagerly=True)\n"
      ],
      "metadata": {
        "id": "JkdcoW_vLow1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL REGRESSION\n",
        "all_features = tf.keras.layers.concatenate(encoded_features)\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(all_features)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(all_inputs, output)\n",
        "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(0.001))"
      ],
      "metadata": {
        "id": "HVsx5ZycuYhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use `rankdir='LR'` to make the graph horizontal.\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n"
      ],
      "metadata": {
        "id": "GVyqNNABLyot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, epochs=5, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "pblhIixEMKbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, ds, df, pcol):\n",
        "  predictions = model.predict(ds)\n",
        "  df[pcol] = predictions\n",
        "  threshold = 0.5\n",
        "  df[f'{pcol}_w'] = (predictions > threshold).astype(int)\n",
        "\n",
        "  # Le reste pourrait être ailleurs\n",
        "def prepare_comparaison(df):\n",
        "  df['win1'] = (df.tgf_pwin_1 > 0.5).astype(int)\n",
        "  df['win_cote'] = (df['pff_rapportDirect_2'] > df['pff_rapportDirect_1']).astype(int)\n",
        "  df['win_ord'] = (df['pff_ord_1'] > df['pff_ord_2']).astype(int)\n",
        "\n",
        "def eval(df, pcol):\n",
        "  print('positifs')\n",
        "  print(len(df[(df[f'{pcol}_w'] == 1) & (df.win1 == 1)]) / len(df[(df.win1 == 1)]))\n",
        "  print(len(df[(df.win_cote == 1) & (df.win1 == 1)]) / len(df[(df.win1 == 1)]))\n",
        "  print(len(df[(df.win_ord == 1) & (df.win1 == 1)]) / len(df[(df.win1 == 1)]))\n",
        "  print('negatifs')\n",
        "  print(len(df[(df[f'{pcol}_w'] == 0) & (df.win1 == 0)]) / len(df[(df.win1 == 0)]))\n",
        "  print(len(df[(df.win_cote == 0) & (df.win1 == 0)]) / len(df[(df.win1 == 0)]))\n",
        "  print(len(df[(df.win_ord == 0) & (df.win1 == 0)]) / len(df[(df.win1 == 0)]))"
      ],
      "metadata": {
        "id": "GPTpNe1kvW0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTS**"
      ],
      "metadata": {
        "id": "oBjUB3qkitM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux selectionner tout les enregistrements ou OS_N_SG_pis_cheval_1 est supérieur à sa valeur médiane\n",
        "\n",
        "median_value = dfraw['OS_N_SG_pis_cheval_1'].median()\n",
        "filtered_df = dfraw[dfraw['OS_N_SG_pis_cheval_1'] < median_value].copy()\n",
        "\n",
        "# prompt: sur ce qui reste que je veux connaitre la valeur moyenne de OS_N_MU_pis_cheval_1 pour chaque quartile de pff_chGainTotal_1\n",
        "\n",
        "# Calculate quartiles for pff_chGainTotal_1\n",
        "filtered_df['quartile'] = pd.qcut(filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'], 4, labels=False)\n",
        "\n",
        "# Group by quartile and calculate the mean of OS_N_MU_pis_cheval_1\n",
        "mean_by_quartile = filtered_df.groupby('quartile')['OS_N_MU_pis_cheval_1'].mean()\n",
        "\n",
        "mean_by_quartile"
      ],
      "metadata": {
        "id": "2LdTb0He1H3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: pour tout les enregistrement où pff_mu_pis_cheval_1 est = 25, je veux que la valeur soit remplacé par 24 si pff_chGainTotal_1 / pfi_chNbCourses_1 < 110000, par 29 si >110000 et <174000, par 32 si >174000 et <285000 et par 36 si > 285000\n",
        "\n",
        "# Create a copy to avoid SettingWithCopyWarning\n",
        "filtered_df = filtered_df.copy()\n",
        "\n",
        "# Apply the conditions and update pff_mu_pis_cheval_1\n",
        "filtered_df.loc[\n",
        "    (filtered_df['pff_mu_pis_cheval_1'] == 25) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] < 110000),\n",
        "    'pff_mu_pis_cheval_1'\n",
        "] = 24\n",
        "\n",
        "filtered_df.loc[\n",
        "    (filtered_df['pff_mu_pis_cheval_1'] == 25) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] >= 110000) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] < 174000),\n",
        "    'pff_mu_pis_cheval_1'\n",
        "] = 29\n",
        "\n",
        "filtered_df.loc[\n",
        "    (filtered_df['pff_mu_pis_cheval_1'] == 25) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] >= 174000) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] < 285000),\n",
        "    'pff_mu_pis_cheval_1'\n",
        "] = 32\n",
        "\n",
        "filtered_df.loc[\n",
        "    (filtered_df['pff_mu_pis_cheval_1'] == 25) &\n",
        "    (filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'] >= 285000),\n",
        "    'pff_mu_pis_cheval_1'\n",
        "] = 36"
      ],
      "metadata": {
        "id": "CzDm5GKW7rBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux connnaitre les bornes des quartiles de pff_chGainTotal_1 / pfi_chNbCourses_1\n",
        "\n",
        "# Calculate quartiles for pff_chGainTotal_1 / pfi_chNbCourses_1\n",
        "filtered_df['quartile_ratio'] = pd.qcut(filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1'], 4, labels=False)\n",
        "\n",
        "# Get the boundaries of each quartile\n",
        "quartiles = filtered_df['pff_chGainTotal_1'] / filtered_df['pfi_chNbCourses_1']\n",
        "quartile_bounds = quartiles.quantile([0.25, 0.5, 0.75])\n",
        "\n",
        "quartile_bounds"
      ],
      "metadata": {
        "id": "oWtTC-0T509W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.tgf_win_1 != 0.5]\n",
        "print(len(df[(df.pfs_dSexe == 'FF') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'FF')]))\n",
        "print(len(df[(df.pfs_dSexe == 'FM') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'FM')]))\n",
        "print(len(df[(df.pfs_dSexe == 'FH') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'FH')]))\n",
        "print(len(df[(df.pfs_dSexe == 'HF') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'HF')]))\n",
        "print(len(df[(df.pfs_dSexe == 'HM') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'HM')]))\n",
        "print(len(df[(df.pfs_dSexe == 'HH') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'HH')]))\n",
        "print(len(df[(df.pfs_dSexe == 'MM') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'MM')]))\n",
        "print(len(df[(df.pfs_dSexe == 'MF') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'MF')]))\n",
        "print(len(df[(df.pfs_dSexe == 'MH') & (df.tgf_win_1 == 1)]) / len(df[(df.pfs_dSexe == 'MH')]))"
      ],
      "metadata": {
        "id": "-JxPSCXLSrcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "test_type_col = train_features['diff_sexe']\n",
        "test_type_layer = get_category_encoding_layer(name='diff_sexe',\n",
        "                                              dataset=train_ds,\n",
        "                                              dtype='string',\n",
        "                                              max_tokens=5)\n",
        "test_type_layer(test_type_col)"
      ],
      "metadata": {
        "id": "opBz9AlEYJEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('classifier_test2.keras')\n",
        "reloaded_model = tf.keras.models.load_model('classifier_test.keras')"
      ],
      "metadata": {
        "id": "1fr54u3MuOVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_ds)\n",
        "predictions"
      ],
      "metadata": {
        "id": "Woj0zG9OvCDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: je veux mettre le résultat des prédictions dans une colonne 'pred' du dataframe d'origine 'test'\n",
        "\n",
        "# Convert predictions to a binary classification (e.g., using a threshold)\n",
        "threshold = 0.0\n",
        "binary_predictions = (predictions > threshold).astype(int)\n",
        "\n",
        "# Add the predictions as a new column 'pred' to the test dataframe\n",
        "test['pred'] = binary_predictions\n",
        "\n",
        "# Print the updated dataframe with predictions\n",
        "test.pred.value_counts()"
      ],
      "metadata": {
        "id": "oclHb5ugvOzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.tgf_win_1.value_counts()"
      ],
      "metadata": {
        "id": "HgZi-D7t9m6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: dans dataframe 'test' je veux une colonne win_cote qui contient 1 si rapport 2 > rapport 1 et 0 sinon\n",
        "\n",
        "test['win_cote'] = (test['diff_cote'] < 0.5).astype(int)\n",
        "test['win_ord'] = (test['diff_ord'] > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "c5tiuljozN9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "16uB0_TIj8GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test[(test.pred == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.tgf_win_1 == 1)]))\n",
        "print(len(test[(test.win_cote == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.tgf_win_1 == 1)]))\n",
        "print(len(test[(test.win_ord == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.tgf_win_1 == 1)]))\n",
        "print(len(test[(test.win_cote == 1) & (test.win_ord == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.tgf_win_1 == 1)]))"
      ],
      "metadata": {
        "id": "0xcyWh37zfuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test[(test.pred == 0) & (test.tgf_win_1 == 0)]) / len(test[(test.tgf_win_1 == 0)]))\n",
        "print(len(test[(test.win_cote == 0) & (test.tgf_win_1 == 0)]) / len(test[(test.tgf_win_1 == 0)]))\n",
        "print(len(test[(test.win_ord == 0) & (test.tgf_win_1 == 0)]) / len(test[(test.tgf_win_1 == 0)]))"
      ],
      "metadata": {
        "id": "WP22Lcrs1ras"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test[(test.pred == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.pred == 1)]))\n",
        "print(len(test[(test.pred2 == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.pred2 == 1)]))\n",
        "print(len(test[(test.win_cote == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.win_cote == 1)]))\n",
        "print(len(test[(test.win_ord == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.win_ord == 1)]))\n",
        "print(len(test[(test.win_cote == 1) & (test.win_ord == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.win_cote == 1) & (test.win_ord == 1)]))\n",
        "print(len(test[(test.win_cote == 0) & (test.pred == 1) & (test.tgf_win_1 == 1)]) / len(test[(test.win_cote == 0) & (test.pred == 1)]))"
      ],
      "metadata": {
        "id": "Ey1A4YjiBntS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}